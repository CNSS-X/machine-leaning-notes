# 炼丹大法与实践笔记 - Day 1

这个笔记是完全公开的。

一个从零开始的炼丹大法与实践笔记。

### 背景

因为毕业设计和项目的原因，一直说要了解一下这个领域但是一直没有动手，这下可以强迫自己把这件事儿做完，也算是要完成自己的一个小目标。

## 关于炼丹大法

From Wikipedia 相关的材料我也并不太大算 COPY and PASTE 了，相信决定来看一看这个领域的同学肯定都是知道机器学习是干什么的。

>机器学习致力于研究如果通过计算手段，利用经验来改善

大致了解了一下学习的路线，炼丹大法并不是那么容易就能学会的，私人认为这并不是几天熬夜学习的事情，涉及到很多的数学问题（可能是大一大二欠的债吧）。但是如果只是想调用封装的算法，这个事情可能会变得很简单，找一个相似的模型源代码，COPY and PASTE 修改参数，增加新的输入。

但是我并不是太想只是使用一下封装好的算法，还是想比较深入了解一下各个算法的理论和机器学习中遇到的问题：比如过拟合和欠拟合造成的问题，LOESS 算法来解决欠拟合问题和 KD TREE 对 LOESS 的改进。当然这些名词你可以都感觉非常懵逼，其实无所谓，我觉得我在这一份笔记中都会说到，尽量用最简单最具体的形式反映出来。

## 机器学习的分类以及基本术语及概念

From：《机器学习》（清华大学出版社）- 周志华

整体的分类，我们根据训练数据是否拥有标记信息，可以分为监督学习和无监督学习两类，从名字看来，无监督学习可能更屌一点，但是我们现在还不知道这两类学习究竟是在做什么，所以接下来我们就准备了解一下这两类学习的具体解决问题和场景。

周志华大佬的西瓜书（《机器学习》），就是以西瓜开始的，所以我们也以西瓜开始这个问题吧！

**这里请大家阅读《机器学习》第一章绪论的 1.1 - 1.4**

### 监督学习 - Supervised Learning

**数据集（data set）**，一个数据集中有很多条关于数据的记录，这些记录是关某一个事件或者对象的描述，我们把一个被描述的对象或者事件成为**实例（instance）**。

对于一个实例来说，他可能有很多的**属性（property）**或者叫**特征（feature）**。这些属性肯定都是有一个取值的，这些取值可以是枚举或者是连续的取值，当然他们就叫**属性值（property value）**。

属性张成的空间我们称之为**属性空间（property space）或 样本空间（sample space）或 输入空间**：那么大家又要问，什么叫张成？张成是谁？可能会有一个更加直观的解释来说明张成：假如属性分别有三个，**（X，Y，Z）**，那么这三个属性可以张成一个三维空间，X 属性对应 X 轴，Y 属性对应 Y 轴，Z 属性对应 Z 轴，那么如果有四个属性，那就会张成一个四个轴向的空间（这就比较抽象了）。但是张成确实是这个意思。

那么对于一个样本空间有三个属性，那么我们可以看成他是一个三维空间，也就是说，这个数据集中的所有的点都可以表示在这个样本空间中，那么一个点表示为（x，y，z），在这个三维空间中，看到（x，y，z），我们很容易猜得到，这个东西应该叫向量xx的。实际上，这个点表示的这个 instance 我们称之为 **feature vector （特征向量）**。

那么其他的概念也就很容被导出了，我们有三个属性，那么也就是说，这个样本空间的**维度（Dimensionality）**是 3。

我们经常说到：机器学习从数据中学习得到某一个**模型（model）**，然后我们可以根据模型去预测一类行为。那么，我们从机器学习中学习到模型这个过程叫**Learning 或者 Training**，训练的时候，肯定是要针对某一些已经收集好的样本进行训练，这些样本叫**Training Sample - 训练样本**，这些样本组成的数据集我们成为**训练集**。

在训练的过程中，我们是为了寻找某一种潜在的规律，但是我们只能找到一种模型，努力去接近这一种未知的潜在规律。这种模型可能并不是特别的正确，我们称之为**假设（hypothesis）**，对应的，真正的内在规律就叫**真相（ground-truth）** 。机器学习的过程就是不断让自己的假设逼近真相。当然模型还有别的名称，比如（小霸王）**学习机 - Learner**，可以看作是样本数据集和参数在空间上的实例化。

那么得到了一个模型，我们能拿来做什么呢？我们能 **预测** 某些事情的结果。假设这个结果是一个布尔结果。也就只有 1 或者 0。我们就需要给每一个 instace 做一个标记，标记这个结果到底是 1 还是 0。那么，我们的结果只有两种情况，那么我们的**标记空间（label space）或者输出空间**的 size 就是 2（只有 0 或者 1）。

接下来，我们的预测什么呢？

假如我们想要把一个已经知道特征的点打上标记获得结果，我们就是在做一种**分类（Classification）**的操作。

如果我们的样本空间不是离散的不像布尔空间这种只有 0 和 1，而是 0 到 1 的这种连续空间，我们预测的连续值就称之为**回归（Regression）**

。。。

### 无监督学习 - Unsupervised Learning

如果说我们不满足于固定的样本空间，有太多的位置属性，我们想要发现这些位置属性，并且成功分类，让自己的模型具有泛化能力。这样，我们的需求实际上就变成了**聚类（Clustering）**。

关于聚类我们就先不多解释了，到时候在说。

## 今天就这么多了

第一天的绪论我们简单复习一下，了解一下这些基本概念，然后留一个印象

如果要了解更详细具体的概念说明：请阅读《机器学习》- 周志华 第一章绪论的 1.1 - 1.4

